{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a07577c",
   "metadata": {},
   "source": [
    "<h1> Linear Regression </h1><br>\n",
    "<h3> What is it ? </h3>\n",
    "<p>\n",
    "    <b>\n",
    "       &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "            Linear Regression is an approach of estimating values of dependent variables from independent variables.In laeman terms just predicting value from one variable to another.<br><br>The idea is that we will be able to extract continous output from continous input which can help understand few things like \n",
    "        &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "        <ul>\n",
    "            <li> Check if their is relationship between the 2 variables (dependent and undependent variables) </li>\n",
    "            <li> Estimate the  value of depndent variable from independent variable </li>\n",
    "        </ul>\n",
    "        <br>\n",
    "        <P> The following figure will shed more light on linear regression:</P><br>\n",
    "        <img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/linear-regression-in-machine-learning.png\">\n",
    "     </b>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c91ef7",
   "metadata": {},
   "source": [
    "<h2> 0. Installing Dependencies </h2><br>\n",
    "<p>     &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "        Run the cell to install dependencies when in new environment or when you need to install new dependencies add to the cell and run it </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94bb5f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install pandas \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4e4feb",
   "metadata": {},
   "source": [
    "<h2> 1. Importing Dependencies </h2><br>\n",
    "<p> Here we will import all the dependencies if more dependencies need to be imported later add in the cell below </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ffd95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from IPython.display import clear_output, display\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2975e5c",
   "metadata": {},
   "source": [
    "<h2> 1. Load Data </h2>\n",
    "\n",
    "<p> &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; This jupyter notebook works with dataset of 'csv' extension and at this stage works on single variable cases so please be aware while sending the dataset </p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_name=input('Enter file directory: ')\n",
    "file_name='Dataset_single_variable.csv'\n",
    "df=pd.read_csv(file_name)\n",
    "X=df[df.columns[0]].to_list()\n",
    "Y=df[df.columns[1]].to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5e7c3",
   "metadata": {},
   "source": [
    "<h2> 2. Linear Regression Algorithm </h2><br>\n",
    "<p>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; \n",
    "    In this notebook we will discuss 2 possible ways to implement Linear Regression they are: \n",
    "    <ul>\n",
    "        <li> Least Squared Method </li>\n",
    "            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Elaboraed in the figure <p>\n",
    "                <img src=\"https://www.investopedia.com/thmb/uebUu8WLq3fv3V_7KAQuX0B_dyo=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/LeastSquaresMethod-3f66319f00a84addb9503457ffee412f.jpg\">\n",
    "        <li> Gradient Decent Method </li>\n",
    "            <p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  Elaboraed in the figure <p>\n",
    "                <img src=\"https://miro.medium.com/max/1400/1*tQTcGTLZqnI5rp3JYO_4NA.png\">\n",
    "    </ul>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "    We will be using R squared method to determine how well the best fit line works \n",
    "    <img src=\"https://www.investopedia.com/thmb/lvCmuo4Is4GX_i7KWIc0S7G5iT8=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/R-Squared-final-cc82c183ea7743538fdeed1986bd00c3.png\">\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba8292",
   "metadata": {},
   "source": [
    "<h2> 2.1.1 Linear Regression using least squared method </h2><br>\n",
    "<h4> What is it ? </h4>\n",
    "    <br>\n",
    "        <p> The least squares method is a statistical procedure to find the best fit for a set of data points by minimizing the sum of the offsets or residuals of points from the plotted curve </p>\n",
    "        <br>\n",
    "        <p> Initially we have equation of line in intercept form </p>\n",
    "        <img src=\"https://ichef.bbci.co.uk/images/ic/1200xn/p0cx7wkx.png\">\n",
    "        <p> We will have a bunch of cords for x and their corresponding y values then we compute m and c as: </p>\n",
    "        \n",
    "<img src =\"https://i.stack.imgur.com/OjlaY.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a340007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_m_c(X,Y):\n",
    "    n=len(X)\n",
    "    X_mean=sum(X)/len(X)\n",
    "    Y_mean=sum(Y)/len(Y)\n",
    "    num=0\n",
    "    den=0\n",
    "    for i in range(len(X)):\n",
    "        num+=(X[i]-X_mean)*(Y[i]-Y_mean)\n",
    "        den+=(X[i]-X_mean)**2\n",
    "    m=num/den\n",
    "    c=Y_mean-m*X_mean\n",
    "    return m,c\n",
    "\n",
    "slope,intercept=compute_m_c(X,Y)\n",
    "print(slope,intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d78410",
   "metadata": {},
   "source": [
    "<h2> 2.1.2 Plotting best fit line </h2>\n",
    "<br>\n",
    "    <p> We are going to plot the distribution along with the best fit line to observe how the overall model looks </p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608d580",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X,Y,color='red')\n",
    "plt.plot(X,[slope*i+intercept for i in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9da2712",
   "metadata": {},
   "source": [
    "<h2> 2.1.3. Calculating R Squared value for best fit line </h2>\n",
    "<br>\n",
    "    <p> R squared value is computed to get how well the best fit line justifies the data </p>\n",
    "    <img src=\"https://www.googleapis.com/download/storage/v1/b/kaggle-forum-message-attachments/o/inbox%2F4688022%2F9c3db3d7f859969f9a7dfa767c3e2026%2FScreenshot%202020-11-25%20202018.png?generation=1606328444707827&alt=media\"><br>\n",
    "    <p> Here y cap is prediction at that point and y dash is mean </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a877e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_y_(m,c,x):\n",
    "    return (m*x+c)\n",
    "\n",
    "def compute_R_squared(m,c,X,Y):\n",
    "    Y_mean=sum(Y)/len(Y)\n",
    "    num=0\n",
    "    den=0\n",
    "    for i in range(len(X)):\n",
    "        num+=(Y[i]-compute_y_(m,c,X[i]))**2\n",
    "        den+=(Y[i]-Y_mean)**2\n",
    "    R_squared=1-(num/den)\n",
    "    return R_squared\n",
    "\n",
    "print(compute_R_squared(slope,intercept,X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8ee77",
   "metadata": {},
   "source": [
    "<h2> 2.2.1 Linear Regression using Gradient Descent </h2><br>\n",
    "<h4> What is it ? </h4>\n",
    "    <br>\n",
    "        <p> This is basically the concept of fitting lines on the dataset in a iterative fashion such that we can get the most optimized line by correcting and learning from mistakes.\n",
    "</p>\n",
    "    <br>\n",
    "    <b> Best way to understand would be to undertand the following image </b>\n",
    "        <img src=\"https://static.javatpoint.com/tutorial/machine-learning/images/gradient-descent-in-machine-learning1.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_ploting(m,x,c):\n",
    "    return (m*x+c)\n",
    "\n",
    "def model_train(X,Y,m,c,epochs,learning_rate):\n",
    "    iterations=epochs*100000 #1epoch=100000 iterations\n",
    "    plot_parameters=[]\n",
    "    for iter in range(1,(iterations+1)):        \n",
    "        D_m=0\n",
    "        D_c=0\n",
    "        for i in range(0,len(X)):\n",
    "            D_m+=(line_ploting(m,X[i],c)-Y[i])*X[i]\n",
    "            D_c+=(line_ploting(m,X[i],c)-Y[i])\n",
    "        \n",
    "        D_m=(D_m)/len(X)\n",
    "        D_c=(D_c)/len(X)\n",
    "        \n",
    "        m=m-learning_rate*D_m\n",
    "        c=c-learning_rate*D_c\n",
    "        #clear_output(wait=True) #This portion is to have single line display \n",
    "        #print(str(iter)+' out of '+str(iterations+1))\n",
    "        if iter%1000000==0:\n",
    "            plot_parameters.append([m,c])\n",
    "\n",
    "    return m,c,plot_parameters\n",
    "\n",
    "def saving_model(m,c):\n",
    "    with open('model.txt','w') as f:\n",
    "        f.write(str(m))\n",
    "        f.write('\\n')\n",
    "        f.write(str(c))    \n",
    "m=0\n",
    "c=0\n",
    "m,c,plot_parameters=model_train(X,Y,m,c,130,0.00001)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e4016",
   "metadata": {},
   "source": [
    "<h2> 2.2.2 Plotting Lines over checkpoints </h2><br>\n",
    "<b> Since Gradient Decent is iterative steps we will see how the data has changed over the various iterations </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006c6df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "index=1\n",
    "for i in plot_parameters:\n",
    "    m=i[0]\n",
    "    c=i[1]\n",
    "    plt.plot(X,[m*j+c for j in X])\n",
    "    \n",
    "for i in plot_parameters: \n",
    "    fig=plt.figure(figsize=(35,35))\n",
    "    plt.subplot(10,5,index)\n",
    "    plt.plot(X,[m*j+c for j in X])\n",
    "    index+=1\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cd80d3",
   "metadata": {},
   "source": [
    "<h2> 2.2.3. Calculating R Squared value for best fit line </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942f6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compute_R_squared(m,c,X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449220e1",
   "metadata": {},
   "source": [
    "<h2> 3. Saving Model </h2>\n",
    "<br>\n",
    "<p> The concept of saving the model is to avoid training again from scratch we save how the progress we have made as a model file in the case of linear regression if we save <b> m </b> and <b> c </b> It should do the trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac683175",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_model(m,c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
